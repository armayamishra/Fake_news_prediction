# Fake_news_prediction

This project focuses on detecting fake news using Natural Language Processing (NLP) and machine learning techniques. The model is built using libraries such as Pandas for data manipulation, NumPy for numerical operations, and regular expressions (re) for text processing. The Natural Language Toolkit (NLTK) is used for text cleaning, specifically for removing stopwords and applying stemming through PorterStemmer. The feature extraction is done using Scikit-learn's TfidfVectorizer, which converts text data into numerical vectors. The dataset is split into training and testing sets using train_test_split, and the classification model is trained using Logistic Regression. The accuracy of the model is evaluated using the accuracy_score metric. This project demonstrates an end-to-end pipeline for detecting fake news, from data preprocessing to model evaluation, using Python's powerful libraries.
